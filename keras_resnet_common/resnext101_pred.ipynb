{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "import keras.backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Add, Input,Dense, Conv2D, DepthwiseConv2D, Activation, Flatten, MaxPooling2D, \\\n",
    "    BatchNormalization, GlobalMaxPooling2D, ZeroPadding2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from imagenet_utils import _obtain_input_shape\n",
    "from keras.engine.topology import get_source_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Set up the GPU memory size to avoid the out-of-memory error\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 4GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the weights links abd hashes \n",
    "BASE_WEIGHTS_PATH = (\n",
    "    'https://github.com/keras-team/keras-applications/releases/download/resnet/')\n",
    "WEIGHTS_HASHES = {\n",
    "    'resnet50': ('2cb95161c43110f7111970584f804107',\n",
    "                 '4d473c1dd8becc155b73f8504c6f6626'),\n",
    "    'resnet101': ('f1aeb4b969a6efcfb50fad2f0c20cfc5',\n",
    "                  '88cf7a10940856eca736dc7b7e228a21'),\n",
    "    'resnet152': ('100835be76be38e30d865e96f2aaae62',\n",
    "                  'ee4c566cf9a93f14d82f913c2dc6dd0c'),\n",
    "    'resnet50v2': ('3ef43a0b657b3be2300d5770ece849e0',\n",
    "                   'fac2f116257151a9d068a22e544a4917'),\n",
    "    'resnet101v2': ('6343647c601c52e1368623803854d971',\n",
    "                    'c0ed64b8031c3730f411d2eb4eea35b5'),\n",
    "    'resnet152v2': ('a49b44d1979771252814e80f8ec446f9',\n",
    "                    'ed17cf2e0169df9d443503ef94b23b33'),\n",
    "    'resnext50': ('67a5b30d522ed92f75a1f16eef299d1a',\n",
    "                  '62527c363bdd9ec598bed41947b379fc'),\n",
    "    'resnext101': ('34fb605428fcc7aa4d62f44404c11509',\n",
    "                   '0f678c91647380debd923963594981b3')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n",
    "    # Define the 1st residual block\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer.\n",
    "        kernel_size: default 3, kernel size of the bottleneck layer.\n",
    "        stride: default 1, stride of the first layer.\n",
    "        conv_shortcut: default True, use convolution shortcut if True,\n",
    "            otherwise identity shortcut.\n",
    "        name: string, block label.\n",
    "    # Return\n",
    "        Output tensor for the residual block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    if conv_shortcut is True:\n",
    "        shortcut = Conv2D(4 * filters, 1, strides=stride, name=name + '_0_conv')(x)\n",
    "        shortcut = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(shortcut)\n",
    "    else:\n",
    "        shortcut = x\n",
    "\n",
    "    x = Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\n",
    "    x = Activation('relu', name=name + '_1_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='SAME', name=name + '_2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\n",
    "    x = Activation('relu', name=name + '_2_relu')(x)\n",
    "\n",
    "    x = Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)\n",
    "\n",
    "    x = Add(name=name + '_add')([shortcut, x])\n",
    "    x = Activation('relu', name=name + '_out')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack1(x, filters, blocks, stride1=2, name=None):\n",
    "    # Define a set of stacked residual blocks\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer in a block.\n",
    "        blocks: integer, blocks in the stacked blocks.\n",
    "        stride1: default 2, stride of the first layer in the first block.\n",
    "        name: string, stack label.\n",
    "    # Return\n",
    "        Output tensor for the stacked blocks.\n",
    "    \"\"\"\n",
    "    x = block1(x, filters, stride=stride1, name=name + '_block1')\n",
    "\n",
    "    for i in range(2, blocks + 1):\n",
    "        x = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block2(x, filters, kernel_size=3, stride=1, conv_shortcut=False, name=None):\n",
    "    # Define the 2nd residual block\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer.\n",
    "        kernel_size: default 3, kernel size of the bottleneck layer.\n",
    "        stride: default 1, stride of the first layer.\n",
    "        conv_shortcut: default False, use convolution shortcut if True,\n",
    "            otherwise identity shortcut.\n",
    "        name: string, block label.\n",
    "    # Return\n",
    "        Output tensor for the residual block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    preact = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_preact_bn')(x)\n",
    "    preact = Activation('relu', name=name + '_preact_relu')(preact)\n",
    "\n",
    "    if conv_shortcut is True:\n",
    "        shortcut = Conv2D(4 * filters, 1, strides=stride, name=name + '_0_conv')(preact)\n",
    "    else:\n",
    "        shortcut = MaxPooling2D(1, strides=stride)(x) if stride > 1 else x\n",
    "\n",
    "    x = Conv2D(filters, 1, strides=1, use_bias=False, name=name + '_1_conv')(preact)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\n",
    "    x = Activation('relu', name=name + '_1_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + '_2_pad')(x)\n",
    "    x = Conv2D(filters, kernel_size, strides=stride, use_bias=False, name=name + '_2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\n",
    "    x = Activation('relu', name=name + '_2_relu')(x)\n",
    "\n",
    "    x = Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n",
    "    x = Add(name=name + '_out')([shortcut, x])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack2(x, filters, blocks, stride1=2, name=None):\n",
    "    # Define the 2nd set of stacked residual blocks.\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer in a block.\n",
    "        blocks: integer, blocks in the stacked blocks.\n",
    "        stride1: default 2, stride of the first layer in the first block.\n",
    "        name: string, stack label.\n",
    "    # Return\n",
    "        Output tensor for the stacked blocks.\n",
    "    \"\"\"\n",
    "    x = block2(x, filters, conv_shortcut=True, name=name + '_block1')\n",
    "\n",
    "    for i in range(2, blocks):\n",
    "        x = block2(x, filters, name=name + '_block' + str(i))\n",
    "\n",
    "    x = block2(x, filters, stride=stride1, name=name + '_block' + str(blocks))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block3(x, filters, kernel_size=3, stride=1, groups=32, conv_shortcut=True, name=None):\n",
    "    # Define the 3rd residual block.\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer.\n",
    "        kernel_size: default 3, kernel size of the bottleneck layer.\n",
    "        stride: default 1, stride of the first layer.\n",
    "        groups: default 32, group size for grouped convolution.\n",
    "        conv_shortcut: default True, use convolution shortcut if True,\n",
    "            otherwise identity shortcut.\n",
    "        name: string, block label.\n",
    "    # Return\n",
    "        Output tensor for the residual block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    if conv_shortcut is True:\n",
    "        shortcut = Conv2D((64 // groups) * filters, 1, strides=stride, use_bias=False, name=name + '_0_conv')(x)\n",
    "        shortcut = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(shortcut)\n",
    "    else:\n",
    "        shortcut = x\n",
    "\n",
    "    x = Conv2D(filters, 1, use_bias=False, name=name + '_1_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\n",
    "    x = Activation('relu', name=name + '_1_relu')(x)\n",
    "\n",
    "    c = filters // groups\n",
    "\n",
    "    x = ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + '_2_pad')(x)\n",
    "    x = DepthwiseConv2D(kernel_size, strides=stride, depth_multiplier=c, use_bias=False, name=name + '_2_conv')(x)\n",
    "\n",
    "    kernel = np.zeros((1, 1, filters * c, filters), dtype=np.float32)\n",
    "\n",
    "    for i in range(filters):\n",
    "        start = (i // c) * c * c + i % c\n",
    "        end = start + c * c\n",
    "        kernel[:, :, start:end:c, i] = 1.\n",
    "\n",
    "    x = Conv2D(filters, 1, use_bias=False, trainable=False,\n",
    "               kernel_initializer={'class_name': 'Constant', 'config': {'value': kernel}},\n",
    "               name=name + '_2_gconv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\n",
    "    x = Activation('relu', name=name + '_2_relu')(x)\n",
    "\n",
    "    x = Conv2D((64 // groups) * filters, 1, use_bias=False, name=name + '_3_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)\n",
    "\n",
    "    x = Add(name=name + '_add')([shortcut, x])\n",
    "    x = Activation('relu', name=name + '_out')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack3(x, filters, blocks, stride1=2, groups=32, name=None):\n",
    "    # Define the 3rd set of stacked residual blocks.\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer in a block.\n",
    "        blocks: integer, blocks in the stacked blocks.\n",
    "        stride1: default 2, stride of the first layer in the first block.\n",
    "        groups: default 32, group size for grouped convolution.\n",
    "        name: string, stack label.\n",
    "    # Return\n",
    "        Output tensor for the stacked blocks.\n",
    "    \"\"\"\n",
    "    x = block3(x, filters, stride=stride1, groups=groups, name=name + '_block1')\n",
    "\n",
    "    for i in range(2, blocks + 1):\n",
    "        x = block3(x, filters, groups=groups, conv_shortcut=False, name=name + '_block' + str(i))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(stack_fn, preact, use_bias, model_name='resnet', include_top=True, weights='imagenet',\n",
    "           input_tensor=None, input_shape=None, pooling=None, num_classes=1000, **kwargs):\n",
    "    # Instantiate the ResNet, ResNetV2, and ResNeXt architecture.\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        stack_fn: a function that returns output tensor for the stacked residual blocks.\n",
    "        preact: whether to use pre-activation or not (True for ResNetV2, False for ResNet and ResNeXt).\n",
    "        use_bias: whether use biases for conv layers or not (True for ResNet/ResNetV2, False for ResNeXt).\n",
    "        model_name: string, model name.\n",
    "        include_top: whether to include the FC layer at the top of the network.\n",
    "        weights: `None` (random initialization), 'imagenet' or the path to any weights.\n",
    "        input_tensor: optional Keras tensor (output of `layers.Input()`)\n",
    "        input_shape: tuple, only to be specified if `include_top` is False.\n",
    "        pooling: Optional mode for feature extraction when `include_top` is `False`.\n",
    "            - `None`: the output of model is the 4D tensor of the last conv layer \n",
    "            - `avg` means global average pooling and the output as a 2D tensor.\n",
    "            - `max` means global max pooling will be applied.\n",
    "        num_classes: specified if `include_top` is True\n",
    "        num_classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights` or invalid input shape.\n",
    "    \"\"\"\n",
    "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `imagenet` '\n",
    "                         '(pre-training on ImageNet), '\n",
    "                         'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and num_classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=32,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    x = ZeroPadding2D(padding=((3,3), (3,3)), name='conv1_pad')(img_input)\n",
    "    x = Conv2D(64, 7, strides=2, use_bias=use_bias, name='conv1_conv')(x)\n",
    "\n",
    "    if preact is False:\n",
    "        x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "        x = Activation('relu', name='conv1_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=((1,1), (1,1)), name='pool1_pad')(x)\n",
    "    x = MaxPooling2D(3, strides=2, name='pool1_pool')(x)\n",
    "\n",
    "    x = stack_fn(x)\n",
    "\n",
    "    if preact is True:\n",
    "        x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='post_bn')(x)\n",
    "        x = Activation('relu', name='post_relu')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = Dense(num_classes, activation='softmax', name='probs')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D(name='max_pool')(x)\n",
    "\n",
    "    # Ensure the model considers any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Build the model.\n",
    "    model = Model(inputs, x, name=model_name)\n",
    "\n",
    "    # Load weights.\n",
    "    if (weights == 'imagenet') and (model_name in WEIGHTS_HASHES):\n",
    "        if include_top:\n",
    "            file_name = model_name + '_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "            file_hash = WEIGHTS_HASHES[model_name][0]\n",
    "        else:\n",
    "            file_name = model_name + '_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "            file_hash = WEIGHTS_HASHES[model_name][1]\n",
    "        weights_path = get_file(file_name,\n",
    "                                BASE_WEIGHTS_PATH + file_name,\n",
    "                                cache_subdir='models',\n",
    "                                file_hash=file_hash)\n",
    "        by_name = True if 'resnext' in model_name else False\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the definitions of the all ResNet variants \n",
    "def ResNet50(include_top=True, weights='imagenet', input_tensor=None, \n",
    "             input_shape=None, pooling=None, num_classes=1000, **kwargs):\n",
    "\n",
    "    def stack_fn(x):\n",
    "        x = stack1(x, 64, 3, stride1=1, name='conv2')\n",
    "        x = stack1(x, 128, 4, name='conv3')\n",
    "        x = stack1(x, 256, 6, name='conv4')\n",
    "        x = stack1(x, 512, 3, name='conv5')\n",
    "\n",
    "        return x\n",
    "\n",
    "    return ResNet(stack_fn, False, True, 'resnet50', include_top, weights,\n",
    "                  input_tensor, input_shape, pooling, num_classes, **kwargs)\n",
    "\n",
    "\n",
    "def ResNet101(include_top=True, weights='imagenet', input_tensor=None, \n",
    "              input_shape=None, pooling=None, classes=1000, **kwargs):\n",
    "\n",
    "    def stack_fn(x):\n",
    "        x = stack1(x, 64, 3, stride1=1, name='conv2')\n",
    "        x = stack1(x, 128, 4, name='conv3')\n",
    "        x = stack1(x, 256, 23, name='conv4')\n",
    "        x = stack1(x, 512, 3, name='conv5')\n",
    "\n",
    "        return x\n",
    "\n",
    "    return ResNet(stack_fn, False, True, 'resnet101', include_top, weights,\n",
    "                  input_tensor, input_shape, pooling, classes, **kwargs)\n",
    "\n",
    "\n",
    "def ResNet152(include_top=True, weights='imagenet', input_tensor=None,\n",
    "              input_shape=None, pooling=None, num_classes=1000, **kwargs):\n",
    "\n",
    "    def stack_fn(x):\n",
    "        x = stack1(x, 64, 3, stride1=1, name='conv2')\n",
    "        x = stack1(x, 128, 8, name='conv3')\n",
    "        x = stack1(x, 256, 36, name='conv4')\n",
    "        x = stack1(x, 512, 3, name='conv5')\n",
    "\n",
    "        return x\n",
    "\n",
    "    return ResNet(stack_fn, False, True, 'resnet152', include_top, weights,\n",
    "                  input_tensor, input_shape, pooling, classes, **kwargs)\n",
    "\n",
    "\n",
    "def ResNet50V2(include_top=True, weights='imagenet', input_tensor=None,\n",
    "               input_shape=None, pooling=None, num_classes=1000, **kwargs):\n",
    "\n",
    "    def stack_fn(x):\n",
    "        x = stack2(x, 64, 3, name='conv2')\n",
    "        x = stack2(x, 128, 4, name='conv3')\n",
    "        x = stack2(x, 256, 6, name='conv4')\n",
    "        x = stack2(x, 512, 3, stride1=1, name='conv5')\n",
    "\n",
    "        return x\n",
    "\n",
    "    return ResNet(stack_fn, True, True, 'resnet50v2', include_top, weights,\n",
    "                  input_tensor, input_shape, pooling, classes, **kwargs)\n",
    "\n",
    "\n",
    "def ResNet101V2(include_top=True, weights='imagenet', input_tensor=None,\n",
    "                input_shape=None, pooling=None, num_classes=1000, **kwargs):\n",
    "\n",
    "    def stack_fn(x):\n",
    "        x = stack2(x, 64, 3, name='conv2')\n",
    "        x = stack2(x, 128, 4, name='conv3')\n",
    "        x = stack2(x, 256, 23, name='conv4')\n",
    "        x = stack2(x, 512, 3, stride1=1, name='conv5')\n",
    "\n",
    "        return x\n",
    "\n",
    "    return ResNet(stack_fn, True, True, 'resnet101v2', include_top, weights,\n",
    "                  input_tensor, input_shape, pooling, classes, **kwargs)\n",
    "\n",
    "\n",
    "def ResNet152V2(include_top=True, weights='imagenet',input_tensor=None,\n",
    "                input_shape=None, pooling=None, num_classes=1000, **kwargs):\n",
    "\n",
    "    def stack_fn(x):\n",
    "        x = stack2(x, 64, 3, name='conv2')\n",
    "        x = stack2(x, 128, 8, name='conv3')\n",
    "        x = stack2(x, 256, 36, name='conv4')\n",
    "        x = stack2(x, 512, 3, stride1=1, name='conv5')\n",
    "\n",
    "        return x\n",
    "\n",
    "    return ResNet(stack_fn, True, True, 'resnet152v2', include_top, weights,\n",
    "                  input_tensor, input_shape, pooling, classes, **kwargs)\n",
    "\n",
    "\n",
    "def ResNeXt50(include_top=True, weights='imagenet', input_tensor=None,\n",
    "              input_shape=None, pooling=None, num_classes=1000, **kwargs):\n",
    "\n",
    "    def stack_fn(x):\n",
    "        x = stack3(x, 128, 3, stride1=1, name='conv2')\n",
    "        x = stack3(x, 256, 4, name='conv3')\n",
    "        x = stack3(x, 512, 6, name='conv4')\n",
    "        x = stack3(x, 1024, 3, name='conv5')\n",
    "\n",
    "        return x\n",
    "\n",
    "    return ResNet(stack_fn, False, False, 'resnext50', include_top, weights,\n",
    "                  input_tensor, input_shape, pooling, classes, **kwargs)\n",
    "\n",
    "\n",
    "def ResNeXt101(include_top=True, weights='imagenet', input_tensor=None,\n",
    "               input_shape=None, pooling=None, num_classes=1000, **kwargs):\n",
    "\n",
    "    def stack_fn(x):\n",
    "        x = stack3(x, 128, 3, stride1=1, name='conv2')\n",
    "        x = stack3(x, 256, 4, name='conv3')\n",
    "        x = stack3(x, 512, 23, name='conv4')\n",
    "        x = stack3(x, 1024, 3, name='conv5')\n",
    "\n",
    "        return x\n",
    "\n",
    "    return ResNet(stack_fn, False, False, 'resnext101', include_top, weights,\n",
    "                  input_tensor, input_shape, pooling, num_classes, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the arguments for the ResNet variants \n",
    "setattr(ResNet50, '__doc__', ResNet.__doc__)\n",
    "setattr(ResNet101, '__doc__', ResNet.__doc__)\n",
    "setattr(ResNet152, '__doc__', ResNet.__doc__)\n",
    "setattr(ResNet50V2, '__doc__', ResNet.__doc__)\n",
    "setattr(ResNet101V2, '__doc__', ResNet.__doc__)\n",
    "setattr(ResNet152V2, '__doc__', ResNet.__doc__)\n",
    "setattr(ResNeXt50, '__doc__', ResNet.__doc__)\n",
    "setattr(ResNeXt101, '__doc__', ResNet.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    # Process any given image\n",
    "    x = image.img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = np.divide(x, 255.0)\n",
    "    x = np.subtract(x, 0.5)\n",
    "    output = np.multiply(x, 2.0)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnext101\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9408        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 128)  0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (DepthwiseC (None, 56, 56, 512)  4608        conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_gconv (Conv2D)   (None, 56, 56, 128)  65536       conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 128)  0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16384       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  32768       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  32768       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 128)  0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (DepthwiseC (None, 56, 56, 512)  4608        conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_gconv (Conv2D)   (None, 56, 56, 128)  65536       conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 128)  0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  32768       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  32768       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 128)  0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (DepthwiseC (None, 56, 56, 512)  4608        conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_gconv (Conv2D)   (None, 56, 56, 128)  65536       conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 128)  0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  32768       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 56, 56, 256)  65536       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 56, 56, 256)  1024        conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 56, 56, 256)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 58, 58, 256)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (DepthwiseC (None, 28, 28, 2048) 18432       conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_gconv (Conv2D)   (None, 28, 28, 256)  524288      conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block1_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 256)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131072      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  131072      conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 256)  131072      conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 256)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 256)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (DepthwiseC (None, 28, 28, 2048) 18432       conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_gconv (Conv2D)   (None, 28, 28, 256)  524288      conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block2_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 256)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  131072      conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 256)  131072      conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 256)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 256)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (DepthwiseC (None, 28, 28, 2048) 18432       conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_gconv (Conv2D)   (None, 28, 28, 256)  524288      conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block3_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 256)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  131072      conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 256)  131072      conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 256)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 256)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (DepthwiseC (None, 28, 28, 2048) 18432       conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_gconv (Conv2D)   (None, 28, 28, 256)  524288      conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 256)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  131072      conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 28, 28, 512)  262144      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 28, 28, 512)  2048        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 28, 28, 512)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 30, 30, 512)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_gconv (Conv2D)   (None, 14, 14, 512)  4194304     conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block1_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 512)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 512)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_gconv (Conv2D)   (None, 14, 14, 512)  4194304     conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block2_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 512)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 512)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_gconv (Conv2D)   (None, 14, 14, 512)  4194304     conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block3_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 512)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 512)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_gconv (Conv2D)   (None, 14, 14, 512)  4194304     conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block4_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 512)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 512)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_gconv (Conv2D)   (None, 14, 14, 512)  4194304     conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block5_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 512)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 512)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_gconv (Conv2D)   (None, 14, 14, 512)  4194304     conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block6_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 512)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 512)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_gconv (Conv2D)   (None, 14, 14, 512)  4194304     conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block7_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 14, 14, 512)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 14, 14, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 14, 14, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 512)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_gconv (Conv2D)   (None, 14, 14, 512)  4194304     conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 14, 14, 512)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 14, 14, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 14, 14, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 512)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_gconv (Conv2D)   (None, 14, 14, 512)  4194304     conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block9_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 14, 14, 512)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 14, 14, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 14, 14, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block10_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 14, 14, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 14, 14, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block11_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 14, 14, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 14, 14, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block12_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 14, 14, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 14, 14, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block13_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 14, 14, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 14, 14, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block14_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 14, 14, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 14, 14, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block15_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 14, 14, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 14, 14, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block16_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 14, 14, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 14, 14, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block17_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 14, 14, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 14, 14, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block18_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 14, 14, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 14, 14, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block19_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 14, 14, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 14, 14, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block20_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 14, 14, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 14, 14, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block21_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 14, 14, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 14, 14, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block22_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 14, 14, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 14, 14, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 512)  524288      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 512)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, 16, 16, 512)  0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Depthwise (None, 14, 14, 8192) 73728       conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_gconv (Conv2D)  (None, 14, 14, 512)  4194304     conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 14, 14, 512)  2048        conv4_block23_2_gconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 14, 14, 512)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 14, 14, 1024) 524288      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 14, 14, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 14, 14, 1024) 0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 14, 14, 1024) 1048576     conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 14, 14, 1024) 4096        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 14, 14, 1024) 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 16, 16, 1024) 0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (DepthwiseC (None, 7, 7, 32768)  294912      conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_gconv (Conv2D)   (None, 7, 7, 1024)   33554432    conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 1024)   4096        conv5_block1_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 1024)   0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2097152     conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   2097152     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 1024)   2097152     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 1024)   4096        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 1024)   0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 1024)   0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (DepthwiseC (None, 7, 7, 32768)  294912      conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_gconv (Conv2D)   (None, 7, 7, 1024)   33554432    conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 1024)   4096        conv5_block2_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 1024)   0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   2097152     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 1024)   2097152     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 1024)   4096        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 1024)   0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 1024)   0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (DepthwiseC (None, 7, 7, 32768)  294912      conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_gconv (Conv2D)   (None, 7, 7, 1024)   33554432    conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 1024)   4096        conv5_block3_2_gconv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 1024)   0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   2097152     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 243,741,608\n",
      "Trainable params: 44,177,704\n",
      "Non-trainable params: 199,563,904\n",
      "__________________________________________________________________________________________________\n",
      "Input image shape: (1, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[('n02123159', 'tiger_cat', 0.57617277), ('n02124075', 'Egyptian_cat', 0.27032915), ('n02123045', 'tabby', 0.092814855), ('n03958227', 'plastic_bag', 0.012121773), ('n03657121', 'lens_cap', 0.006207084)]]\n"
     ]
    }
   ],
   "source": [
    "# Call the specfic ResNext101 model \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    model = ResNeXt101(include_top=True, weights='imagenet', input_tensor=None, \n",
    "                       input_shape=(224,224,3), pooling=None, num_classes=1000)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    img_path = '/home/mike/Documents/keras_resnet_common/images/cat.jpg'\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    output = preprocess_input(img)\n",
    "\n",
    "    print('Input image shape:', output.shape)\n",
    "\n",
    "    preds = model.predict(output)\n",
    "    print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the GPU Memory\n",
    "from numba import cuda\n",
    "\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
